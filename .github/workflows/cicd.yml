name: Upload to Databricks using API

on: 
  push:
    branches: main

jobs:
  build-and-deploy:
    environment:
      name: dev
    runs-on: ubuntu-22.04.4

    steps: 
    - name: Variables Used
      run: |
        echo Databricks Host: ${{ vars.DATABRICKS_HOST }}
        echo Remote Save Location: "${{ vars.REMOTE_FILE_PATH }}"

    - name: Checkout code
      uses: actions/checkout@v3

    - name: Set up Python
      uses: actions/setup-python@v3
      with:
        python-version: "3.10"

    - name: Build Artifact
      uses: actions/upload-artifact@v4.2.0
      with:
        name: Build_Artifacts
        path: |
          ${{ github.workspace }}
          !**/.github/**
          !**/.git/**
          !**/.gitignore/**
          !**/README.md

    - name: Download Build Artifacts
      uses: actions/download-artifact@v4
      with:
        name: Build_Artifacts
        path: "${{github.workspace}}/artifacts"

    # - name: install-databricks-cli
    #   run: |
    #     curl -fsSL https://raw.githubusercontent.com/databricks/setup-cli/main/install.sh | sh
    #   shell: bash
    
    - name: install-databricks-cli
      run: |
        pip install databricks-cli==0.18.0
      shell: bash

    - name: Import Code to Databricks
      run: |
        databricks workspace import-dir --overwrite "${LOCAL_FILE_PATH}" "${REMOTE_FILE_PATH}" --debug

      env:
          DATABRICKS_HOST: ${{ vars.DATABRICKS_HOST }}
          DATABRICKS_TOKEN: ${{ secrets.DB_TOKEN }}
          LOCAL_FILE_PATH: "${{ github.workspace }}/artifacts"
          REMOTE_FILE_PATH: "${{ vars.REMOTE_FILE_PATH }}"